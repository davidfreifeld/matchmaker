{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5e32d8",
   "metadata": {
    "_sphinx_cell_id": "95af47f7-4665-46a1-88b0-cc6a33966610"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from pydantic import BaseModel\n",
    "import json\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4908a7",
   "metadata": {
    "_sphinx_cell_id": "4cf91723-d78b-4a34-a35a-2a3d16d447ec"
   },
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6ba469",
   "metadata": {
    "_sphinx_cell_id": "3cf847b5-49a8-48da-988c-c1b15fe12dde"
   },
   "outputs": [],
   "source": [
    "def save_df_to_csv(samples_df: pd.DataFrame, name: str = 'samples', directory: str = './data/'):\n",
    "    timestamp_str = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "    samples_df.to_csv(f\"{directory}{name}_{timestamp_str}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29987ea6",
   "metadata": {
    "_sphinx_cell_id": "41fee400-d362-4c2d-9096-ac6d773aeab5"
   },
   "outputs": [],
   "source": [
    "def list_files(directory: str) -> List[str]:\n",
    "    \"\"\"Return all file names (not directories) in the given directory.\"\"\"\n",
    "    path = Path(directory).expanduser()\n",
    "    return [p.name for p in path.iterdir() if p.is_file()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d56744",
   "metadata": {
    "_sphinx_cell_id": "f7020119-87ff-4402-8c0f-b0f664b71076"
   },
   "outputs": [],
   "source": [
    "def get_last_saved_timestamp(directory: str = './data/'):\n",
    "    filenames = list_files(directory)\n",
    "    matches = [ re.search(r'.*?(\\d{14})\\.csv$', fn) for fn in filenames ]\n",
    "    timestamps = [ int(m.group(1)) for m in matches if m is not None ]\n",
    "    return str(max(timestamps))\n",
    "\n",
    "# get_last_saved_timestamp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_sphinx_cell_id": "2909ddfe-aeca-4ada-a163-18cfce39f78a"
   },
   "outputs": [],
   "source": [
    "def load_df(timestamp: str, name: str = 'samples', directory: str = './data/') -> pd.DataFrame:\n",
    "    return pd.read_csv(f\"{directory}{name}_{timestamp}.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79574e40",
   "metadata": {
    "_sphinx_cell_id": "355ef63a-adbc-4a7e-863f-9498fe371ff8"
   },
   "outputs": [],
   "source": [
    "def load_latest_df(name: str = 'samples', directory: str = './data/') -> pd.DataFrame:\n",
    "    timestamp = get_last_saved_timestamp(directory=directory)\n",
    "    return load_df(timestamp=timestamp, name=name, directory=directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d45db00",
   "metadata": {
    "_sphinx_cell_id": "ea1ff1a2-3170-4f39-b65b-ba9d4f5ca264"
   },
   "source": [
    "## Do Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_sphinx_cell_id": "ccc37081-cb6a-4b2f-b0fb-f69834239d92"
   },
   "outputs": [],
   "source": [
    "# read in env vars from the .env file\n",
    "load_dotenv(override=True)\n",
    "\n",
    "PROMPT_ID_SYNTH_GEN = os.environ['PROMPT_ID_SYNTH_GEN']\n",
    "PROMPT_ID_SUFFIX_LIST = ['SMALL', 'MEDIUM', 'LARGE']\n",
    "\n",
    "# connect and get an OpenAI client\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_sphinx_cell_id": "fa7a58dc-7dca-4c7a-b8fb-a8c0cd54a752"
   },
   "outputs": [],
   "source": [
    "class BioSnippet(BaseModel):\n",
    "    text_snippet: str\n",
    "    source: str\n",
    "    is_match: bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_sphinx_cell_id": "2a77b7a9-344a-4f85-a235-7802d1dd9329"
   },
   "outputs": [],
   "source": [
    "class UserWithLabeledSnippets(BaseModel):\n",
    "    first_name: str\n",
    "    last_name: str\n",
    "    city: str\n",
    "    state: str\n",
    "    birth_year: int\n",
    "    snippets: list[BioSnippet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_sphinx_cell_id": "b8ee3739-5fe2-4d35-a8ab-6dc249991d9e"
   },
   "outputs": [],
   "source": [
    "class ListOfUsersWithLabeledSnippets(BaseModel):\n",
    "    users: list[UserWithLabeledSnippets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_sphinx_cell_id": "a842e338-cd1d-41ea-8113-226716f706f5"
   },
   "outputs": [],
   "source": [
    "def generate_synthetic_samples(prompt_id, n_people=10) -> pd.DataFrame:\n",
    "    resp = client.responses.parse(\n",
    "        prompt={\"id\": prompt_id},\n",
    "        input=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"\"\"\n",
    "                    Generate {n_people} example fictional people. \n",
    "                    - Each person should have 5 to 10 snippets. \n",
    "                    - Each snippet should represent a brief bio of the fictional person found via googling. e.g. a whitepages.com listing, an instagram bio, a reddit post, etc.\n",
    "                    - Each snippet should either actually match the person, and hence have a label of is_match=True, or it should be a close, but not actual, match, and have is_match=False.\n",
    "                    - About half of the snippets per person should be true matches, and half should be false.\n",
    "                    - Each snippet should have a source (e.g. whitepages, reddit, instagram)\n",
    "                \"\"\",\n",
    "            },\n",
    "        ],\n",
    "        text_format=ListOfUsersWithLabeledSnippets,\n",
    "    )   \n",
    "    users_list = json.loads(resp.output_text)['users']\n",
    "\n",
    "    samples_df = pd.DataFrame(columns=['First Name', 'Last Name', 'City', 'State', 'Birth Year', 'Text Snippet', 'Source', 'Is Match'])\n",
    "    for user in users_list:\n",
    "        for snippet in user['snippets']:\n",
    "            new_row = {\n",
    "                \"First Name\": user['first_name'],\n",
    "                \"Last Name\": user['last_name'],\n",
    "                \"City\": user['city'],\n",
    "                \"State\": user['state'],\n",
    "                \"Birth Year\": user['birth_year'],\n",
    "                \"Text Snippet\": snippet['text_snippet'],\n",
    "                \"Source\": snippet['source'],\n",
    "                \"Is Match\": snippet['is_match'],\n",
    "            }\n",
    "            samples_df = pd.concat([samples_df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "\n",
    "    save_df_to_csv(samples_df)\n",
    "\n",
    "    return samples_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_sphinx_cell_id": "a54295fc-eaac-488f-9a41-9eaee747ca4f"
   },
   "outputs": [],
   "source": [
    "samples_df = generate_synthetic_samples(os.environ['PROMPT_ID_SYNTH_GEN'], n_people=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_sphinx_cell_id": "cf7f4598-4004-4845-bbec-1763625edeb3"
   },
   "outputs": [],
   "source": [
    "class MatchScoreResponse(BaseModel):\n",
    "    match_prob: float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_sphinx_cell_id": "cb845b1b-d128-4593-819b-ae43f7854331"
   },
   "outputs": [],
   "source": [
    "def get_match_prob(row, prompt_id_suffix):\n",
    "    first_name = row['First Name']\n",
    "    last_name = row['Last Name']\n",
    "    city = row['City']\n",
    "    state = row['State']\n",
    "    birth_year = row['Birth Year']\n",
    "    snippet = row['Text Snippet']\n",
    "    source = row['Source']\n",
    "\n",
    "    input_message = f\"\"\"\n",
    "        Here is the profile of a person. (The current year is 2025). \n",
    "        - First Name: {first_name}\n",
    "        - Last Name: {last_name}\n",
    "        - City: {city}\n",
    "        - State: {state}\n",
    "        - Birth Year: {birth_year}\n",
    "        Here is a snippet found online via googling that person: \"{snippet}\"\n",
    "\n",
    "        It is from {source}.\n",
    "\n",
    "        Please output the probability (a number from 0 to 1 rounded to two decimal places) that the snippet is \n",
    "        referring to that specific person. 1 means you are absolutely sure that it is a match, and 0 means that you\n",
    "        are absolutely sure it is not.\n",
    "    \"\"\"\n",
    "\n",
    "    resp = client.responses.parse(\n",
    "        prompt={\"id\": os.environ[f\"PROMPT_ID_SCORER_{prompt_id_suffix}\"]},\n",
    "        input=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": input_message\n",
    "            },\n",
    "        ],\n",
    "        text_format=MatchScoreResponse,\n",
    "    )   \n",
    "\n",
    "    return float(json.loads(resp.output_text)['match_prob'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_sphinx_cell_id": "ba7af38e-54b2-42e0-8fee-0c403d858e1c"
   },
   "outputs": [],
   "source": [
    "def get_all_match_probs(df, prompt_id_suffix):\n",
    "    match_probs_list = []\n",
    "    for _, row in df.iterrows():\n",
    "        match_prob = get_match_prob(row, prompt_id_suffix)\n",
    "        match_probs_list.append(match_prob)\n",
    "    \n",
    "    df[f\"Match Prob {prompt_id_suffix}\"] = pd.Series(match_probs_list, index=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_sphinx_cell_id": "1c0697c6-b8fa-4974-858b-3d00c2dba2ce"
   },
   "outputs": [],
   "source": [
    "def run_all_prompt_scorers(df):\n",
    "    for prompt_id_suffix in PROMPT_ID_SUFFIX_LIST:\n",
    "        get_all_match_probs(df, prompt_id_suffix=prompt_id_suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_sphinx_cell_id": "b4ffa3c8-e3ad-45f0-aac2-a100b98cb28f"
   },
   "outputs": [],
   "source": [
    "run_all_prompt_scorers(samples_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_sphinx_cell_id": "4821be84-6904-4926-a689-0073986b6a3e"
   },
   "outputs": [],
   "source": [
    "samples_df[['Is Match', 'Match Prob SMALL', 'Match Prob MEDIUM', 'Match Prob LARGE']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_sphinx_cell_id": "f42d1907-4dc4-493b-9006-b0df6d01bc74"
   },
   "outputs": [],
   "source": [
    "cols = [\"Match Prob SMALL\", \"Match Prob MEDIUM\", \"Match Prob LARGE\"]\n",
    "df_true = samples_df[samples_df[\"Is Match\"] == True]\n",
    "df_false = samples_df[samples_df[\"Is Match\"] == False]\n",
    "\n",
    "fig, axes = plt.subplots(nrows=3, ncols=1, figsize=(8, 10), sharex=False)\n",
    "for ax, col in zip(axes, cols):\n",
    "    bins = np.linspace(0.0, 1.0, 21)  # 20 bins\n",
    "    ax.hist(df_true.loc[df_true[col] >= 0.0, col], bins=bins, alpha=0.6, label=\"Is Match = True\", color=\"tab:blue\")\n",
    "    ax.hist(df_false.loc[df_false[col] >= 0.0, col], bins=bins, alpha=0.6, label=\"Is Match = False\", color=\"tab:orange\")\n",
    "    ax.set_title(col)\n",
    "    ax.set_ylabel(\"Count\")\n",
    "    ax.legend()\n",
    "\n",
    "axes[-1].set_xlabel(\"Probability\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_sphinx_cell_id": "f1670458-623d-4e2d-9a4f-746cc1516ef0"
   },
   "outputs": [],
   "source": [
    "for prompt_id_suffix in PROMPT_ID_SUFFIX_LIST:\n",
    "    col = f\"Match Prob {prompt_id_suffix}\"\n",
    "    probs_true = samples_df.loc[samples_df['Is Match'], col]\n",
    "    probs_false = samples_df.loc[~(samples_df['Is Match'].astype(bool)), col]\n",
    "    \n",
    "    print(f\"Using {prompt_id_suffix} Model:\")\n",
    "    print(f\"True Matches:\\t{probs_true.mean():.2f}\")\n",
    "    print(f\"False Matches:\\t{probs_false.mean():.2f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_sphinx_cell_id": "25fbd63e-c351-4f74-8d94-97388fb18acb"
   },
   "outputs": [],
   "source": [
    "def get_accuracy(df, prompt_id_suffix, thresh: float = 0.5) -> float:\n",
    "    predictions = df[f\"Match Prob {prompt_id_suffix}\"] > thresh\n",
    "    print(f\"Total observations:\\t{len(df)}\")\n",
    "    print(f\"True match count:\\t{df['Is Match'].sum()}\")\n",
    "    print(f\"Predicted true matches:\\t{predictions.sum()}\")\n",
    "    print(f\"Correct predcitions:\\t{(predictions == df['Is Match']).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_sphinx_cell_id": "d0b81915-b7ce-4d28-873a-c83f520becdc"
   },
   "outputs": [],
   "source": [
    "get_accuracy(samples_df, \"SMALL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_sphinx_cell_id": "4fe0046b-3d7e-453a-a0f3-f093c4c3faa5"
   },
   "outputs": [],
   "source": [
    "get_accuracy(samples_df, \"MEDIUM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_sphinx_cell_id": "87114729-285d-4659-803c-25891c9e2446"
   },
   "outputs": [],
   "source": [
    "get_accuracy(samples_df, \"LARGE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "_sphinx_cell_id": "47c5272a-0412-43b9-8a8c-4c8c4c6cfbc5"
   },
   "outputs": [],
   "source": [
    "def bce_loss(df, prompt_id_suffix) -> float:\n",
    "    epsilon = 1e-6\n",
    "    y = df['Is Match'].astype(float)\n",
    "    probs = np.clip(df[f\"Match Prob {prompt_id_suffix}\"], epsilon, 1-epsilon)\n",
    "    loss = (y * np.log(probs) + (1 - y) * np.log(1 - probs)).sum()\n",
    "    # print(loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "_sphinx_cell_id": "faacc7ff-8885-4233-80b3-1429cb02111b"
   },
   "outputs": [],
   "source": [
    "def calc_and_print_bce_loss(df, prompt_id_suffix):\n",
    "    loss = bce_loss(df, prompt_id_suffix)\n",
    "    print(f\"{prompt_id_suffix} BCE Loss: \\t{loss:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "_sphinx_cell_id": "24eb9d18-0303-413a-985d-b2524696936c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMALL BCE Loss: \t-78.68\n",
      "MEDIUM BCE Loss: \t-19.59\n",
      "LARGE BCE Loss: \t-39.70\n"
     ]
    }
   ],
   "source": [
    "_ = [ calc_and_print_bce_loss(samples_df, prompt_id_suffix) for prompt_id_suffix in PROMPT_ID_SUFFIX_LIST ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_sphinx_cell_id": "a3acc991-d9f5-491f-aaa9-71d7d3612796"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "matchmaker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
